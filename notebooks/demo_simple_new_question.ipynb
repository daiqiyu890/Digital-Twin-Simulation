{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Twin Simulation - Simple Demo\n",
    "\n",
    "This notebook presents simple examples of how to leverage the persona to simulate survey responses of new questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai.api_key:\n",
    "    print(\"⚠️ Please set your OPENAI_API_KEY in the .env file or environment\")\n",
    "else:\n",
    "    print(\"✅ OpenAI API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 30 persona summaries from Hugging Face...\n",
      "✅ Loaded 30 personas\n",
      "\n",
      "Sample persona (first 500 chars):\n",
      "==================================================\n",
      "The following is a description of a person.\n",
      "\n",
      "The person's demographics are the following...\n",
      "Geographic region: South (TX, OK, AR, LA, KY, TN, MS, AL, WV, DC, MD, DE, VA, NC, SC, GA, FL)\n",
      "Gender: Male\n",
      "Age: 18-29\n",
      "Education level: Some college, no degree\n",
      "Race: White\n",
      "Citizen of the US: Yes\n",
      "Marital status: Never been married\n",
      "Religion: Protestant\n",
      "Religious attendance: Once or twice a month\n",
      "Political affiliation: Republican\n",
      "Income: $100,000 or more\n",
      "Political views: Conservative\n",
      "Household size: 4\n",
      "Employm...\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "NUM_PERSONAS = 30  # Number of personas to load (max ~2058 available)\n",
    "\n",
    "# Download and load persona summaries directly from Hugging Face\n",
    "def load_personas(num_personas=30):\n",
    "    \"\"\"Download and load persona summaries directly from Hugging Face dataset.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "    except ImportError:\n",
    "        print(\"Installing datasets library...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([\"pip\", \"install\", \"datasets\"])\n",
    "        from datasets import load_dataset\n",
    "    \n",
    "    print(f\"Loading {num_personas} persona summaries from Hugging Face...\")\n",
    "    \n",
    "    # Load the dataset directly from Hugging Face\n",
    "    dataset = load_dataset(\"LLM-Digital-Twin/Twin-2K-500\", 'full_persona', split='data')\n",
    "    \n",
    "    # Extract personas\n",
    "    personas = {}\n",
    "    pids = dataset[\"pid\"]\n",
    "    persona_summaries = dataset[\"persona_summary\"]\n",
    "    \n",
    "    # Load requested number of personas\n",
    "    for i in range(min(num_personas, len(pids))):\n",
    "        pid = pids[i]\n",
    "        summary = persona_summaries[i]\n",
    "        \n",
    "        if summary is not None:\n",
    "            personas[f\"pid_{pid}\"] = summary\n",
    "    \n",
    "    return personas\n",
    "\n",
    "# Load personas\n",
    "personas = load_personas(NUM_PERSONAS)\n",
    "\n",
    "print(f\"✅ Loaded {len(personas)} personas\")\n",
    "\n",
    "# Show sample of first persona\n",
    "if personas:\n",
    "    first_persona = list(personas.values())[0]\n",
    "    print(f\"\\nSample persona (first 500 chars):\")\n",
    "    print(\"=\"*50)\n",
    "    print(first_persona[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Questions and Simulate Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_responses(personas, template):\n",
    "    rows = []\n",
    "    for pid, persona in personas.items():\n",
    "        user_msg = template.format(persona=persona)\n",
    "        try:\n",
    "            resp = openai.chat.completions.create(\n",
    "                model=\"gpt-4.1-mini-2025-04-14\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "                    {\"role\": \"user\",   \"content\": user_msg}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=5  # enough for a single number\n",
    "            )\n",
    "            answer = resp.choices[0].message.content.strip()\n",
    "            print(f\"✅ {pid}: {answer}\")\n",
    "        except Exception as e:\n",
    "            answer = f\"Error: {e}\"\n",
    "            print(f\"❌ {pid}: {answer}\")\n",
    "        rows.append({\"persona_id\": pid, \"answer\": answer})\n",
    "        time.sleep(0.5)  # gentle rate‑limit\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pid_574: 3\n",
      "✅ pid_2001: 3\n",
      "✅ pid_1710: 2\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MESSAGE = \"You, AI, are an expert in predicting human responses to questions. You are given a persona profile and a question, and also a format instructions that specifies the type of answer you need to provide. You need to answer the question as the persona would answer it, based on the persona profile and the format instructions.\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "{persona}\n",
    "\n",
    "QUESTION: Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations. Please complete the statements below.\n",
    "\n",
    "It is ___ that Linda is a teacher in an elementary school.\n",
    "\n",
    "Options:\n",
    "  1 = Extremely improbable\n",
    "  2 = Very improbable\n",
    "  3 = Somewhat probable\n",
    "  4 = Moderately probable\n",
    "  5 = Very probable\n",
    "  6 = Extremely probable\n",
    "\n",
    "FORMAT INSTRUCTIONS: Only return the number, no other text.\n",
    "\"\"\"\n",
    "\n",
    "df_1 = simulate_responses(personas, USER_PROMPT_TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simulate_responses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      1\u001b[39m SYSTEM_MESSAGE = \u001b[33m\"\u001b[39m\u001b[33mYou, AI, are an expert in predicting human responses to questions. You are given a persona profile and a question, and also a format instructions that specifies the type of answer you need to provide. You need to answer the question as the persona would answer it, based on the persona profile and the format instructions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m USER_PROMPT_TEMPLATE = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;132;01m{persona}\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \u001b[33mFORMAT INSTRUCTIONS: Only return the number, no other text.\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m df_1 = \u001b[43msimulate_responses\u001b[49m(personas, USER_PROMPT_TEMPLATE)\n",
      "\u001b[31mNameError\u001b[39m: name 'simulate_responses' is not defined"
     ]
    }
   ],
   "source": [
    "SYSTEM_MESSAGE = \"You, AI, are an expert in predicting human responses to questions. You are given a persona profile and a question, and also a format instructions that specifies the type of answer you need to provide. You need to answer the question as the persona would answer it, based on the persona profile and the format instructions.\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "{persona}\n",
    "\n",
    "QUESTION: Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations. Please complete the statements below.\n",
    "\n",
    "It is ___ that Linda is a teacher in an elementary school\n",
    "\n",
    "Options:\n",
    "  1 = Extremely improbable\n",
    "  2 = Very improbable\n",
    "  3 = Somewhat probable\n",
    "  4 = Moderately probable\n",
    "  5 = Very probable\n",
    "  6 = Extremely probable\n",
    "\n",
    "FORMAT INSTRUCTIONS: Only return the number, no other text.\n",
    "\"\"\"\n",
    "\n",
    "df_1 = simulate_responses(personas, USER_PROMPT_TEMPLATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digital-twin-simulation-o7RtJ_Ea-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
