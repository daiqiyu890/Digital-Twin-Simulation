# Evaluation Configuration for text-base-simulation-GPT4.1-mini
# This runs the full evaluation pipeline on the GPT-4.1-mini simulation results

# Base directory for the simulation trial
trial_dir: "simulation_trials/text-base-simulation-GPT4.1-mini"

# Model information (used in plots and reports)
model_name: "gpt-4.1-mini"

# Process all personas (set to null for all, or a number to limit)
max_personas: null  # Process all personas

# Wave configurations - define input patterns and output paths
waves:
  wave1_3:
    # Input pattern from original answer blocks
    input_pattern: "data/mega_persona_json/answer_blocks/pid_{pid}_wave4_Q_wave1_3_A.json"
    # Output paths for different formats (relative to trial_dir)
    output_csv: "${trial_dir}/csv_comparison/responses_wave1_3.csv"
    output_csv_formatted: "${trial_dir}/csv_comparison/csv_formatted/responses_wave1_3_formatted.csv"
    output_csv_labeled: "${trial_dir}/csv_comparison/csv_formatted_label/responses_wave1_3_label_formatted.csv"
    
  wave4:
    input_pattern: "data/mega_persona_json/answer_blocks/pid_{pid}_wave4_Q_wave4_A.json"
    output_csv: "${trial_dir}/csv_comparison/responses_wave4.csv"
    output_csv_formatted: "${trial_dir}/csv_comparison/csv_formatted/responses_wave4_formatted.csv"
    output_csv_labeled: "${trial_dir}/csv_comparison/csv_formatted_label/responses_wave4_label_formatted.csv"
    
  llm_imputed:
    # LLM imputed data from the trial
    input_pattern: "${trial_dir}/answer_blocks_llm_imputed/pid_{pid}_wave4_Q_wave1_3_A.json"
    output_csv: "${trial_dir}/csv_comparison/responses_llm_imputed.csv"
    output_csv_formatted: "${trial_dir}/csv_comparison/csv_formatted/responses_llm_imputed_formatted.csv"
    output_csv_labeled: "${trial_dir}/csv_comparison/csv_formatted_label/responses_llm_imputed_label_formatted.csv"

# Benchmark configuration for formatting
benchmark_csv: "data/wave_csv/wave_4_numbers_anonymized.csv"
column_mapping: "evaluation/column_mapping.csv"

# Question mapping output
save_question_mapping: true
question_mapping_output: "${trial_dir}/csv_comparison/question_mapping.csv"

# Randdollar breakdown for pricing analysis
generate_randdollar_breakdown: true
randdollar_output: "${trial_dir}/csv_comparison/randdollar_breakdown.csv"

# Evaluation settings (for downstream scripts)
evaluation:
  # Output directory for evaluation results
  output_dir: "${trial_dir}/accuracy_evaluation"
  
  # Model name for plots and reports
  model_name: "gpt-4.1-mini"
  
  # MAD plot title template
  mad_plot_title: "Digital Twin Simulation - GPT-4.1-mini"